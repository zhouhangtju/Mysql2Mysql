server:
  tomcat:
    uri-encoding: UTF-8
    threads:
      max: 200
      min-spare: 30
    connection-timeout: 5000ms
  port: 8081
  servlet:
    context-path: /

mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.nologging.NoLoggingImpl

#spring:
#  #MySQL???
#  datasource:
#      type: com.alibaba.druid.pool.DruidDataSource
#      druid:
#        driver-class-name: com.mysql.cj.jdbc.Driver
#        url: jdbc:mysql://localhost:3306/safety?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
#        username: root
#  #      password: 'OoZh1234!@#$'
#        password: root
#        initial-size: 8
#        max-active: 16
#        min-idle: 8
#        max-wait: 60000
#        test-while-idle: true
#        test-on-borrow: false
#        test-on-return: false

spring:
  datasource:
    dynamic:
      primary: db1 #设置默认的数据源或者数据源组,默认值即为master
      strict: false
      datasource:
        db1:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://localhost:3306/safety?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&useSSL=false
          username: root
          password: 'OoZh1234!@#$'
        db2:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://10.209.44.27:7001/ssa?characterEncoding=utf8&autoReconnect=true&useSSL=false
          username: asiainfo
          password: 'asiainfo_1#'
#          driver-class-name: com.github.housepower.jdbc.ClickHouseDriver
#          url: jdbc:clickhouse://10.72.194.54:9002/default
#          username: root
#          password: 'asiainfo_1#'
#
#  kafka:
#    bootstrap-servers: 188.106.25.14:9092
#    producer:
#      # 发生错误后，消息重发的次数。
#      retries: 0
#      #当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。
#      #batch-size: 16384
#      # 设置生产者内存缓冲区的大小。
#      #buffer-memory: 33554432
#      # 键的序列化方式
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      # 值的序列化方式
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
#      # acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
#      # acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
#      # acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
#      #acks: 0
#    consumer:
#      # 键的反序列化方式
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      # 值的反序列化方式
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      max-poll-records: 640
#      fetch-min-size: 10485760
#      fetch-max-wait: 5000
#    listener:
#      ack-mode: manual
#      type: batch
