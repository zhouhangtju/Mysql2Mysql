server:
  tomcat:
    uri-encoding: UTF-8
    threads:
      max: 200
      min-spare: 30
    connection-timeout: 5000ms
  port: 8081
  servlet:
    context-path: /


spring:
  datasource:
    dynamic:
      primary: db1 #设置默认的数据源或者数据源组,默认值即为master
      strict: false
      datasource:
        db1:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://localhost:3306/safety?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
          username: root
          password: root

#  kafka:
#    bootstrap-servers: 172.18.17.113:9092
#    producer:
#        # 发生错误后，消息重发的次数。
#      retries: 0
#      #当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。
#      batch-size: 16384
#      # 设置生产者内存缓冲区的大小。
#      buffer-memory: 33554432
#      # 键的序列化方式
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      # 值的序列化方式
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
#      # acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
#      # acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
#      # acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
#      #acks: 0
#    consumer:
#      # 键的反序列化方式
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      # 值的反序列化方式
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      max-poll-records: 640
#      fetch-min-size: 10485760
#      fetch-max-wait: 5000
#      auto-commit-interval:
#    listener:
#      ack-mode: manual
#      type: batch

